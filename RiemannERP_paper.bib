
@article{duda_pattern_2001,
	title = {Pattern classification. 2nd},
	journal = {Edition. New York},
	author = {Duda, Richard O and Hart, Peter E and Stork, David G},
	year = {2001}
}

@article{blankertz_optimizing_2008,
	title = {Optimizing spatial filters for robust {EEG} single-trial analysis},
	volume = {25},
	doi = {doi:10.1109/MSP.2008.4408441},
	journal = {IEEE Signal Processing Magazine},
	author = {Blankertz, B. and Tomioka, R. and Lemm, S. and Kawanabe, M. and Müller, K.-R.},
	year = {2008},
	pages = {41--56}
}

@book{luck_introduction_2005,
	title = {An introduction to the event-related potential technique.},
	publisher = {MIT press},
	author = {Luck, Steven J},
	year = {2005}
}

@article{arsigny_geometric_2007,
	title = {Geometric {Means} in a {Novel} {Vector} {Space} {Structure} on {Symmetric} {Positive}‐{Definite} {Matrices}},
	volume = {29},
	issn = {0895-4798},
	url = {http://epubs.siam.org/doi/abs/10.1137/050637996},
	doi = {10.1137/050637996},
	abstract = {In this work we present a new generalization of the geometric mean of positive numbers on symmetric positive‐definite matrices, called Log‐Euclidean. The approach is based on two novel algebraic structures on symmetric positive‐definite matrices: first, a lie group structure which is compatible with the usual algebraic properties of this matrix space; second, a new scalar multiplication that smoothly extends the Lie group structure into a vector space structure. From bi‐invariant metrics on the Lie group structure, we define the Log‐Euclidean mean from a Riemannian point of view. This notion coincides with the usual Euclidean mean associated with the novel vector space structure. Furthermore, this means corresponds to an arithmetic mean in the domain of matrix logarithms. We detail the invariance properties of this novel geometric mean and compare it to the recently introduced affine‐invariant mean. The two means have the same determinant and are equal in a number of cases, yet they are not identical in general. Indeed, the Log‐Euclidean mean has a larger trace whenever they are not equal. Last but not least, the Log‐Euclidean mean is much easier to compute.},
	number = {1},
	urldate = {2017-11-29},
	journal = {SIAM Journal on Matrix Analysis and Applications},
	author = {Arsigny, V. and Fillard, P. and Pennec, X. and Ayache, N.},
	month = jan,
	year = {2007},
	pages = {328--347},
	file = {Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/XJLPEZ4W/Arsigny et al. - 2007 - Geometric Means in a Novel Vector Space Structure .pdf:application/pdf;Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/6BA2Z5GM/050637996.html:text/html}
}

@article{barachant_classification_2013,
	title = {Classification of covariance matrices using a {Riemannian}-based kernel for {BCI} applications},
	volume = {112},
	url = {https://hal.archives-ouvertes.fr/hal-00820475},
	doi = {10.1016/j.neucom.2012.12.039},
	abstract = {The use of spatial covariance matrix as a feature is investigated for motor imagery EEG-based classification in Brain-Computer Interface applications. A new kernel is derived by establishing a connection with the Riemannian geometry of symmetric positive definite matrices. Different kernels are tested, in combination with support vector machines, on a past BCI competition dataset. We demonstrate that this new approach outperforms significantly state of the art results, effectively replacing the traditional spatial filtering approach.},
	urldate = {2018-02-12},
	journal = {Neurocomputing},
	author = {Barachant, Alexandre and Bonnet, Stéphane and Congedo, Marco and Jutten, Christian},
	month = jul,
	year = {2013},
	keywords = {Kernel, Covariance Matrix, Support Vector Machine, Riemannian geometry, brain-computer interfaces},
	pages = {172--178},
	file = {HAL PDF Full Text:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/YG4WK6KA/Barachant et al. - 2013 - Classification of covariance matrices using a Riem.pdf:application/pdf}
}

@article{yger_riemannian_2017,
	title = {Riemannian {Approaches} in {Brain}-{Computer} {Interfaces}: {A} {Review}},
	volume = {25},
	issn = {1534-4320},
	shorttitle = {Riemannian {Approaches} in {Brain}-{Computer} {Interfaces}},
	doi = {10.1109/TNSRE.2016.2627016},
	abstract = {Although promising from numerous applications, current brain-computer interfaces (BCIs) still suffer from a number of limitations. In particular, they are sensitive to noise, outliers and the non-stationarity of electroencephalographic (EEG) signals, they require long calibration times and are not reliable. Thus, new approaches and tools, notably at the EEG signal processing and classification level, are necessary to address these limitations. Riemannian approaches, spearheaded by the use of covariance matrices, are such a very promising tool slowly adopted by a growing number of researchers. This article, after a quick introduction to Riemannian geometry and a presentation of the BCI-relevant manifolds, reviews how these approaches have been used for EEG-based BCI, in particular for feature representation and learning, classifier design and calibration time reduction. Finally, relevant challenges and promising research directions for EEG signal classification in BCIs are identified, such as feature tracking on manifold or multi-task learning.},
	number = {10},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Yger, F. and Berar, M. and Lotte, F.},
	month = oct,
	year = {2017},
	keywords = {Brain–computer interface (BCI), electroencephalography (EEG), noise, Manifolds, Calibration, EEG signal classification, learning (artificial intelligence), medical signal processing, signal classification, Geometry, EEG signal processing, Earth, Riemannian approaches, Riemannian geometry, Symmetric matrices, brain-computer interfaces, calibration time reduction, classification, classifier design, covariance matrices, electroencephalographic signals, electroencephalography, feature representation, feature tracking, multi-task learning, reviews, source extraction, subspaces, Covariance matrices},
	pages = {1753--1762},
	file = {IEEE Xplore Abstract Record:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/HPWS4SLJ/7740054.html:text/html;IEEE Xplore Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/QFERMY2L/Yger et al. - 2017 - Riemannian Approaches in Brain-Computer Interfaces.pdf:application/pdf}
}

@article{zanini_transfer_2018,
	title = {Transfer {Learning}: {A} {Riemannian} {Geometry} {Framework} {With} {Applications} to {Brain}–{Computer} {Interfaces}},
	volume = {65},
	issn = {0018-9294},
	shorttitle = {Transfer {Learning}},
	doi = {10.1109/TBME.2017.2742541},
	abstract = {Objective: This paper tackles the problem of transfer learning in the context of electroencephalogram (EEG)-based brain-computer interface (BCI) classification. In particular, the problems of cross-session and cross-subject classification are considered. These problems concern the ability to use data from previous sessions or from a database of past users to calibrate and initialize the classifier, allowing a calibration-less BCI mode of operation. Methods: Data are represented using spatial covariance matrices of the EEG signals, exploiting the recent successful techniques based on the Riemannian geometry of the manifold of symmetric positive definite (SPD) matrices. Cross-session and cross-subject classification can be difficult, due to the many changes intervening between sessions and between subjects, including physiological, environmental, as well as instrumental changes. Here, we propose to affine transform the covariance matrices of every session/subject in order to center them with respect to a reference covariance matrix, making data from different sessions/subjects comparable. Then, classification is performed both using a standard minimum distance to mean classifier, and through a probabilistic classifier recently developed in the literature, based on a density function (mixture of Riemannian Gaussian distributions) defined on the SPD manifold. Results: The improvements in terms of classification performances achieved by introducing the affine transformation are documented with the analysis of two BCI datasets. Conclusion and significance: Hence, we make, through the affine transformation proposed, data from different sessions and subject comparable, providing a significant improvement in the BCI transfer learning problem.},
	number = {5},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Zanini, P. and Congedo, M. and Jutten, C. and Said, S. and Berthoumieu, Y.},
	month = may,
	year = {2018},
	keywords = {Brain–computer interface (BCI), electroencephalography (EEG), Manifolds, Electroencephalography, learning (artificial intelligence), medical signal processing, probabilistic classifier, signal classification, Geometry, Symmetric matrices, brain-computer interfaces, covariance matrices, electroencephalography, Gaussian distribution, Covariance matrices, affine transformation, BCI datasets, BCI transfer learning problem, classification performances, classifier, cross-session classification, cross-subject classification, density function, EEG-based BCI classification, electroencephalogram-based brain-computer interface classification, Electronic mail, geometry, mixtures of Gaussian, Probabilistic logic, reference covariance matrix, Riemannian Gaussian distributions, riemannian geometry, Riemannian geometry framework, spatial covariance matrices, SPD matrices, symmetric positive definite matrices},
	pages = {1107--1116},
	file = {IEEE Xplore Abstract Record:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/PI3GBKXH/8013808.html:text/html;IEEE Xplore Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/RVC45UM9/Zanini et al. - 2018 - Transfer Learning A Riemannian Geometry Framework.pdf:application/pdf}
}

@article{congedo_new_2013,
	title = {A {New} {Generation} of {Brain}-{Computer} {Interface} {Based} on {Riemannian} {Geometry}},
	language = {en},
	author = {Congedo, Marco and Barachant, Alexandre and Andreev, Anton},
	year = {2013},
	pages = {33},
	file = {Congedo et al. - A New Generation of Brain-Computer Interface Based.pdf:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/USYBW2PN/Congedo et al. - A New Generation of Brain-Computer Interface Based.pdf:application/pdf}
}

@article{chavarriaga_learning_2010,
	title = {Learning {From} {EEG} {Error}-{Related} {Potentials} in {Noninvasive} {Brain}-{Computer} {Interfaces}},
	volume = {18},
	doi = {10.1109/TNSRE.2010.2053387},
	abstract = {We describe error-related potentials generated while a human user monitors the performance of an external agent and discuss their use for a new type of brain-computer interaction. In this approach, single trial detection of error-related electroencephalography (EEG) potentials is used to infer the optimal agent behavior by decreasing the probability of agent decisions that elicited such potentials. Contrasting with traditional approaches, the user acts as a critic of an external autonomous system instead of continuously generating control commands. This sets a cognitive monitoring loop where the human directly provides information about the overall system performance that, in turn, can be used for its improvement. We show that it is possible to recognize erroneous and correct agent decisions from EEG (average recognition rates of 75.8\% and 63.2\%, respectively), and that the elicited signals are stable over long periods of time (from 50 to {\textgreater} 600 days). Moreover, these performances allow to infer the optimal behavior of a simple agent in a brain-computer interaction paradigm after a few trials.},
	number = {4},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	author = {Chavarriaga, R. and Millan, J. d R.},
	month = aug,
	year = {2010},
	keywords = {bioelectric potentials, electroencephalography (EEG), learning, Communication system control, Control systems, Algorithms, Brain, Brain computer interfaces, Brain–computer interface, EEG, Electroencephalography, Electrooculography, Evoked Potentials, Humans, Learning, Monitoring, User-Computer Interface, handicapped aids, learning (artificial intelligence), medical signal processing, reinforcement learning, brain-computer interfaces, electroencephalography, Spatiotemporal phenomena, agent decisions, cognitive monitoring loop, error-related potentials, external autonomous system, Neural prosthesis, noninvasive brain-computer interfaces, System performance},
	pages = {381--388},
	file = {IEEE Xplore Abstract Record:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/2Q86HLI6/5491194.html:text/html;IEEE Xplore Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/9CHUAGL5/Chavarriaga and Millan - 2010 - Learning From EEG Error-Related Potentials in Noni.pdf:application/pdf}
}

@article{iturrate_latency_2014,
	title = {Latency correction of error-related potentials reduces {BCI} calibration time},
	abstract = {Calibration of brain-machine interfaces exploiting event-related potentials has to be performed for each experimental paradigm. Even if these signals have been used in previous experiments with diﬀerent protocols. We show that use of signals from previous experiments can reduce the calibration time for single-trial classiﬁcation of error-related potentials. Compensating latency variations across tasks yield up to a 50\% reduction the training period in new experiments without decrease in online performance compared to the standard training.},
	language = {en},
	author = {Iturrate, Inaki and Chavarriaga, Ricardo and Montesano, Luis and Minguez, Javier},
	year = {2014},
	pages = {4},
	file = {2014_OnlineLatencyCorrection.pdf:/home/ruslan/Documents/articles/2014_OnlineLatencyCorrection.pdf:application/pdf}
}

@inproceedings{barachant_common_2010,
	title = {Common {Spatial} {Pattern} revisited by {Riemannian} geometry},
	doi = {10.1109/MMSP.2010.5662067},
	abstract = {This paper presents a link between the well known Common Spatial Pattern (CSP) algorithm and Riemannian geometry in the context of Brain Computer Interface (BCI). It will be shown that CSP spatial filtering and Log variance features extraction can be resumed as a computation of a Riemann distance in the space of covariances matrices. This fact yields to highlight several approximations with respect to the space topology. According to these conclusions, we propose an improvement of classical CSP method.},
	booktitle = {2010 {IEEE} {International} {Workshop} on {Multimedia} {Signal} {Processing}},
	author = {Barachant, Alexandre and Bonnet, Stphane and Congedo, Marco and Jutten, Christian},
	month = oct,
	year = {2010},
	keywords = {Eigenvalues and eigenfunctions, spatial filtering, spatial filters, Electroencephalography, feature extraction, Geometry, Riemannian geometry, Symmetric matrices, brain-computer interfaces, covariance matrices, Approximation methods, brain computer interface, common spatial pattern algorithm, covariance matrix, Covariance matrix, Feature extraction, log variance feature extraction},
	pages = {472--476},
	file = {IEEE Xplore Abstract Record:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/DDQJLWBE/5662067.html:text/html;IEEE Xplore Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/L42ZNLGC/Barachant et al. - 2010 - Common Spatial Pattern revisited by Riemannian geo.pdf:application/pdf}
}

@article{polich_relationship_1997,
	title = {On the relationship between {EEG} and {P}300: individual differences, aging, and ultradian rhythms},
	volume = {26},
	issn = {0167-8760},
	shorttitle = {On the relationship between {EEG} and {P}300},
	url = {http://www.sciencedirect.com/science/article/pii/S0167876097007721},
	doi = {10.1016/S0167-8760(97)00772-1},
	abstract = {The literature on the relationship between background EEG and event-related brain potentials (ERPs) is reviewed, with the conclusion that variation in the former can contribute to individual variability in the latter. The effects of background EEG activity on the P300 component are then described using the results of three experiments. Study 1 assayed the association between EEG spectral power/mean frequency and P300 amplitude/latency measures in young adults. For the slower delta, theta, and alpha bands generally strong correlations were obtained for both types of measures. Study 2 employed similar techniques to assess a large sample of adults who varied in age from 20–80+ years. EEG power in the slower bands was correlated positively with P300 amplitude across the age range, but few effects for mean frequency/component latency were observed. Study 3 measured a group of young adults ten times very 20 min to assess for temporal changes in the relationship between EEG and ERPs. The correlations between spectral power and P300 amplitude measures were found to vary in a manner that suggested the influence of ultradian rhythms on neuroelectric activity. Taken together, the findings from all three study indicate that background EEG variation contributes significantly to the individual variability of the P300 ERP. Theoretical and applied implications of the findings are discussed.© 1997 Elsevier Science B.V.},
	language = {en},
	number = {1},
	urldate = {2019-10-30},
	journal = {International Journal of Psychophysiology},
	author = {Polich, J},
	month = jun,
	year = {1997},
	keywords = {Aging, EEG, ERP, P300, ERD, Spectral power analysis, Ultradian rhythms, Variability},
	pages = {299--317},
	file = {ScienceDirect Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/UUJ3PT78/Polich - 1997 - On the relationship between EEG and P300 individu.pdf:application/pdf;ScienceDirect Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/VEMDVCF6/S0167876097007721.html:text/html}
}

@article{wolpaw_braincomputer_2002,
	title = {Brain–computer interfaces for communication and control},
	volume = {113},
	issn = {1388-2457},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245702000573},
	doi = {10.1016/S1388-2457(02)00057-3},
	abstract = {For many years people have speculated that electroencephalographic activity or other electrophysiological measures of brain function might provide a new non-muscular channel for sending messages and commands to the external world – a brain–computer interface (BCI). Over the past 15 years, productive BCI research programs have arisen. Encouraged by new understanding of brain function, by the advent of powerful low-cost computer equipment, and by growing recognition of the needs and potentials of people with disabilities, these programs concentrate on developing new augmentative communication and control technology for those with severe neuromuscular disorders, such as amyotrophic lateral sclerosis, brainstem stroke, and spinal cord injury. The immediate goal is to provide these users, who may be completely paralyzed, or ‘locked in’, with basic communication capabilities so that they can express their wishes to caregivers or even operate word processing programs or neuroprostheses. Present-day BCIs determine the intent of the user from a variety of different electrophysiological signals. These signals include slow cortical potentials, P300 potentials, and mu or beta rhythms recorded from the scalp, and cortical neuronal activity recorded by implanted electrodes. They are translated in real-time into commands that operate a computer display or other device. Successful operation requires that the user encode commands in these signals and that the BCI derive the commands from the signals. Thus, the user and the BCI system need to adapt to each other both initially and continually so as to ensure stable performance. Current BCIs have maximum information transfer rates up to 10–25bits/min. This limited capacity can be valuable for people whose severe disabilities prevent them from using conventional augmentative communication methods. At the same time, many possible applications of BCI technology, such as neuroprosthesis control, may require higher information transfer rates. Future progress will depend on: recognition that BCI research and development is an interdisciplinary problem, involving neurobiology, psychology, engineering, mathematics, and computer science; identification of those signals, whether evoked potentials, spontaneous rhythms, or neuronal firing rates, that users are best able to control independent of activity in conventional motor output pathways; development of training methods for helping users to gain and maintain that control; delineation of the best algorithms for translating these signals into device commands; attention to the identification and elimination of artifacts such as electromyographic and electro-oculographic activity; adoption of precise and objective procedures for evaluating BCI performance; recognition of the need for long-term as well as short-term assessment of BCI performance; identification of appropriate BCI applications and appropriate matching of applications and users; and attention to factors that affect user acceptance of augmentative technology, including ease of use, cosmesis, and provision of those communication and control capacities that are most important to the user. Development of BCI technology will also benefit from greater emphasis on peer-reviewed research publications and avoidance of the hyperbolic and often misleading media attention that tends to generate unrealistic expectations in the public and skepticism in other researchers. With adequate recognition and effective engagement of all these issues, BCI systems could eventually provide an important new communication and control option for those with motor disabilities and might also give those without disabilities a supplementary control channel or a control channel useful in special circumstances.},
	language = {en},
	number = {6},
	urldate = {2019-10-30},
	journal = {Clinical Neurophysiology},
	author = {Wolpaw, Jonathan R and Birbaumer, Niels and McFarland, Dennis J and Pfurtscheller, Gert and Vaughan, Theresa M},
	month = jun,
	year = {2002},
	keywords = {Rehabilitation, Brain–computer interface, Electroencephalography, Augmentative communication, Brain–machine interface, Neuroprosthesis},
	pages = {767--791},
	file = {ScienceDirect Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/JPY7JKHN/Wolpaw et al. - 2002 - Brain–computer interfaces for communication and co.pdf:application/pdf;ScienceDirect Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/32UQ72GB/S1388245702000573.html:text/html}
}

@article{iturrate_task-dependent_2013,
	title = {Task-dependent signal variations in {EEG} error-related potentials for brain–computer interfaces},
	volume = {10},
	issn = {1741-2552},
	url = {https://doi.org/10.1088%2F1741-2560%2F10%2F2%2F026024},
	doi = {10.1088/1741-2560/10/2/026024},
	abstract = {Objective. A major difficulty of brain–computer interface (BCI) technology is dealing with the noise of EEG and its signal variations. Previous works studied time-dependent non-stationarities for BCIs in which the user’s mental task was independent of the device operation (e.g., the mental task was motor imagery and the operational task was a speller). However, there are some BCIs, such as those based on error-related potentials, where the mental and operational tasks are dependent (e.g., the mental task is to assess the device action and the operational task is the device action itself). The dependence between the mental task and the device operation could introduce a new source of signal variations when the operational task changes, which has not been studied yet. The aim of this study is to analyse task-dependent signal variations and their effect on EEG error-related potentials.Approach. The work analyses the EEG variations on the three design steps of BCIs: an electrophysiology study to characterize the existence of these variations, a feature distribution analysis and a single-trial classification analysis to measure the impact on the final BCI performance.Results and significance. The results demonstrate that a change in the operational task produces variations in the potentials, even when EEG activity exclusively originated in brain areas related to error processing is considered. Consequently, the extracted features from the signals vary, and a classifier trained with one operational task presents a significant loss of performance for other tasks, requiring calibration or adaptation for each new task. In addition, a new calibration for each of the studied tasks rapidly outperforms adaptive techniques designed in the literature to mitigate the EEG time-dependent non-stationarities.},
	language = {en},
	number = {2},
	urldate = {2019-10-30},
	journal = {Journal of Neural Engineering},
	author = {Iturrate, I. and Montesano, L. and Minguez, J.},
	month = mar,
	year = {2013},
	pages = {026024},
	file = {IOP Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/7LJIVHRQ/Iturrate et al. - 2013 - Task-dependent signal variations in EEG error-rela.pdf:application/pdf}
}

@inproceedings{lotte_learning_2010,
	title = {Learning from other subjects helps reducing {Brain}-{Computer} {Interface} calibration time},
	doi = {10.1109/ICASSP.2010.5495183},
	abstract = {A major limitation of Brain-Computer Interfaces (BCI) is their long calibration time, as much data from the user must be collected in order to tune the BCI for this target user. In this paper, we propose a new method to reduce this calibration time by using data from other subjects. More precisely, we propose an algorithm to regularize the Common Spatial Patterns (CSP) and Linear Discriminant Analysis (LDA) algorithms based on the data from a subset of automatically selected subjects. An evaluation of our approach showed that our method significantly outperformed the standard BCI design especially when the amount of data from the target user is small. Thus, our approach helps in reducing the amount of data needed to achieve a given performance level.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Lotte, Fabien and Guan, Cuntai},
	month = mar,
	year = {2010},
	note = {ISSN: 2379-190X, 1520-6149, 1520-6149},
	keywords = {Vectors, Brain computer interfaces, Calibration, Computer interfaces, Electroencephalography, Linear discriminant analysis, learning (artificial intelligence), statistical analysis, brain-computer interfaces, brain computer interface, Covariance matrix, Brain-Computer Interfaces (BCI), calibration time, common spatial pattern, linear discriminant analysis, Machine learning algorithms, regularization, Spatial filters, subject data, subject to subject transfer, subjectto-subject transfer, Unsupervised learning},
	pages = {614--617},
	file = {IEEE Xplore Abstract Record:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/RIAGPMK6/5495183.html:text/html;IEEE Xplore Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/V7IS8NSJ/Lotte and Guan - 2010 - Learning from other subjects helps reducing Brain-.pdf:application/pdf}
}

@article{thompson_classifier-based_2013,
	title = {Classifier-based latency estimation: a novel way to estimate and predict {BCI} accuracy},
	volume = {10},
	issn = {1741-2560},
	shorttitle = {Classifier-based latency estimation},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3650625/},
	doi = {10.1088/1741-2560/10/1/016006},
	abstract = {Objective
Brain-computer interfaces (BCIs) that detect event-related potentials (ERPs) rely on classification schemes that are vulnerable to latency jitter, a phenomenon known to occur with ERPs such as the P300 response. The objective of this work was to investigate the role that latency jitter plays in BCI classification.

Approach
We developed a novel method, classifier-based latency estimation (CBLE), based on a generalization of Woody filtering. The technique works by presenting the time-shifted data to the classifier, and using the time shift that corresponds to the maximal classifier score.

Main results
The variance of CBLE estimates correlates significantly (p {\textless} 10−42) with BCI accuracy in the Farwell-Donchin BCI paradigm. Additionally, CBLE predicts same-day accuracy, even from small datasets or datasets that have already been used for classifier training, better than the accuracy on the small dataset (p {\textless} 0.05). The technique should be relatively classifier-independent, and the results were confirmed on two linear classifiers.

Significance
The results suggest that latency jitter may be an important cause of poor BCI performance, and methods that correct for latency jitter may improve that performance. CBLE can also be used to decrease the amount of data needed for accuracy estimation, allowing research on effects with shorter timescales.},
	number = {1},
	urldate = {2019-10-30},
	journal = {Journal of neural engineering},
	author = {Thompson, David E and Warschausky, Seth and Huggins, Jane E},
	month = feb,
	year = {2013},
	pmid = {23234797},
	pmcid = {PMC3650625},
	pages = {016006},
	file = {PubMed Central Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/S3MIBR9Q/Thompson et al. - 2013 - Classifier-based latency estimation a novel way t.pdf:application/pdf}
}

@article{bradley_use_1997,
	title = {The use of the area under the {ROC} curve in the evaluation of machine learning algorithms},
	volume = {30},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320396001422},
	doi = {10.1016/S0031-3203(96)00142-2},
	abstract = {In this paper we investigate the use of the area under the receiver operating characteristic (ROC) curve (AUC) as a performance measure for machine learning algorithms. As a case study we evaluate six machine learning algorithms (C4.5, Multiscale Classifier, Perceptron, Multi-layer Perceptron, k-Nearest Neighbours, and a Quadratic Discriminant Function) on six “real world” medical diagnostics data sets. We compare and discuss the use of AUC to the more conventional overall accuracy and find that AUC exhibits a number of desirable properties when compared to overall accuracy: increased sensitivity in Analysis of Variance (ANOVA) tests; a standard error that decreased as both AUC and the number of test samples increased; decision threshold independent; and it is invariant to a priori class probabilities. The paper concludes with the recommendation that AUC be used in preference to overall accuracy for “single number” evaluation of machine learning algorithms.},
	language = {en},
	number = {7},
	urldate = {2019-10-30},
	journal = {Pattern Recognition},
	author = {Bradley, Andrew P.},
	month = jul,
	year = {1997},
	keywords = {Cross-validation, Accuracy measures, Standard error, The area under the ROC curve (AUC), The ROC curve, Wilcoxon statistic},
	pages = {1145--1159},
	file = {ScienceDirect Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/42V2M3VL/Bradley - 1997 - The use of the area under the ROC curve in the eva.pdf:application/pdf;ScienceDirect Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/M3H3CWEF/S0031320396001422.html:text/html}
}

@inproceedings{arico_evaluation_2013,
	title = {Evaluation of the {Latency} {Jitter} of {P}300 {Evoked} {Potentials} during ({C})overt {Attention} {BCI}.},
	booktitle = {Proceedings of {TOBI} {Workshop} {IV}},
	author = {Aricò, Pietro and Aloise, Fabio and Schettini, Francesca and Salinari, Serenella and Mattia, Donatella and Cincotti, Febo},
	year = {2013}
}

@article{iturrate_spatio-temporal_2011,
	title = {Spatio-{Temporal} {Filtering} for {EEG} {Error} {Related} {Potentials}},
	abstract = {This paper presents a new ﬁlter for EEG Event-Related Potentials that relies on spatiotemporal features. The results are analyzed with error-related potentials, and compared to the original signal and with the independent component analysis spatial ﬁlter. Additionally, the obtained features are used for single-trial classiﬁcation, showing that it is possible to obtain high classiﬁcation accuracies with a very low number of features.},
	language = {en},
	author = {Iturrate, I and Montesano, L and Chavarriaga, R},
	year = {2011},
	pages = {4},
	file = {IturrateMoChMiMi11a.pdf:/home/ruslan/Documents/articles/IturrateMoChMiMi11a.pdf:application/pdf}
}

@inproceedings{sommer_manifold_2010,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Manifold {Valued} {Statistics}, {Exact} {Principal} {Geodesic} {Analysis} and the {Effect} of {Linear} {Approximations}},
	isbn = {978-3-642-15567-3},
	doi = {10.1007/978-3-642-15567-3_4},
	abstract = {Manifolds are widely used to model non-linearity arising in a range of computer vision applications. This paper treats statistics on manifolds and the loss of accuracy occurring when linearizing the manifold prior to performing statistical operations. Using recent advances in manifold computations, we present a comparison between the non-linear analog of Principal Component Analysis, Principal Geodesic Analysis, in its linearized form and its exact counterpart that uses true intrinsic distances. We give examples of datasets for which the linearized version provides good approximations and for which it does not. Indicators for the differences between the two versions are then developed and applied to two examples of manifold valued data: outlines of vertebrae from a study of vertebral fractures and spacial coordinates of human skeleton end-effectors acquired using a stereo camera and tracking software.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer},
	author = {Sommer, Stefan and Lauze, François and Hauberg, Søren and Nielsen, Mads},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	year = {2010},
	keywords = {Hand Position, Human Skeleton, Stereo Camera, Tangent Space, Vertebral Fracture},
	pages = {43--56},
	file = {Springer Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/YL82CUN3/Sommer et al. - 2010 - Manifold Valued Statistics, Exact Principal Geodes.pdf:application/pdf}
}

@book{berger_panoramic_2003,
	address = {Berlin Heidelberg},
	title = {A {Panoramic} {View} of {Riemannian} {Geometry}},
	isbn = {978-3-540-65317-2},
	url = {https://www.springer.com/gp/book/9783540653172},
	abstract = {Riemannian geometry has today become a vast and important subject. This new book of Marcel Berger sets out to introduce readers to most of the living topics of the field and convey them quickly to the main results known to date. These results are stated without detailed proofs but the main ideas involved are described and motivated. This enables the reader to obtain a sweeping panoramic view of almost the entirety of the field. However, since a Riemannian manifold is, even initially, a subtle object, appealing to highly non-natural concepts, the first three chapters devote themselves to introducing the various concepts and tools of Riemannian geometry in the most natural and motivating way, following in particular Gauss and Riemann.},
	language = {en},
	urldate = {2019-10-31},
	publisher = {Springer-Verlag},
	author = {Berger, Marcel},
	year = {2003},
	doi = {10.1007/978-3-642-18245-7},
	file = {Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/QK35GEVM/9783540653172.html:text/html}
}

@article{chen_shrinkage_2010,
	title = {Shrinkage {Algorithms} for {MMSE} {Covariance} {Estimation}},
	volume = {58},
	issn = {1053-587X, 1941-0476},
	doi = {10.1109/TSP.2010.2053029},
	abstract = {We address covariance estimation in the sense of minimum mean-squared error (MMSE) when the samples are Gaussian distributed. Specifically, we consider shrinkage methods which are suitable for high dimensional problems with a small number of samples (large p small n). First, we improve on the Ledoit-Wolf (LW) method by conditioning on a sufficient statistic. By the Rao-Blackwell theorem, this yields a new estimator called RBLW, whose mean-squared error dominates that of LW for Gaussian variables. Second, to further reduce the estimation error, we propose an iterative approach which approximates the clairvoyant shrinkage estimator. Convergence of this iterative method is established and a closed form expression for the limit is determined, which is referred to as the oracle approximating shrinkage (OAS) estimator. Both RBLW and OAS estimators have simple expressions and are easily implemented. Although the two methods are developed from different perspectives, their structure is identical up to specified constants. The RBLW estimator provably dominates the LW method for Gaussian samples. Numerical simulations demonstrate that the OAS approach can perform even better than RBLW, especially when n is much less than p . We also demonstrate the performance of these techniques in the context of adaptive beamforming.},
	number = {10},
	journal = {IEEE Transactions on Signal Processing},
	author = {Chen, Yilun and Wiesel, Ami and Eldar, Yonina C. and Hero, Alfred O.},
	month = oct,
	year = {2010},
	keywords = {Array signal processing, numerical simulations, Computer science, Statistics, Gaussian distribution, Covariance matrix, adaptive beamforming, Ambient intelligence, array signal processing, Beamforming, convergence, covariance analysis, covariance estimation, Estimation error, Gaussian distributed, Iron, iterative method, iterative methods, Iterative methods, least mean squares methods, Ledoit-Wolf method, minimum mean-squared error, minimum mean-squared error (MMSE), MMSE, oracle approximating shrinkage estimator, Permission, Rao-Blackwell theorem, shrinkage, shrinkage algorithms, Yield estimation},
	pages = {5016--5029},
	file = {IEEE Xplore Abstract Record:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/KIUL8WLC/5484583.html:text/html;IEEE Xplore Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/I8RPR87U/Chen et al. - 2010 - Shrinkage Algorithms for MMSE Covariance Estimatio.pdf:application/pdf}
}

@article{iturrate_latency_2014-1,
	title = {Latency correction of event-related potentials between different experimental protocols},
	volume = {11},
	issn = {1741-2552},
	url = {https://doi.org/10.1088%2F1741-2560%2F11%2F3%2F036005},
	doi = {10.1088/1741-2560/11/3/036005},
	abstract = {Objective. A fundamental issue in EEG event-related potentials (ERPs) studies is the amount of data required to have an accurate ERP model. This also impacts the time required to train a classifier for a brain–computer interface (BCI). This issue is mainly due to the poor signal-to-noise ratio and the large fluctuations of the EEG caused by several sources of variability. One of these sources is directly related to the experimental protocol or application designed, and may affect the amplitude or latency of ERPs. This usually prevents BCI classifiers from generalizing among different experimental protocols. In this paper, we analyze the effect of the amplitude and the latency variations among different experimental protocols based on the same type of ERP. Approach. We present a method to analyze and compensate for the latency variations in BCI applications. The algorithm has been tested on two widely used ERPs (P300 and observation error potentials), in three experimental protocols in each case. We report the ERP analysis and single-trial classification. Main results. The results obtained show that the designed experimental protocols significantly affect the latency of the recorded potentials but not the amplitudes. Significance. These results show how the use of latency-corrected data can be used to generalize the BCIs, reducing the calibration time when facing a new experimental protocol.},
	language = {en},
	number = {3},
	urldate = {2019-10-31},
	journal = {Journal of Neural Engineering},
	author = {Iturrate, I. and Chavarriaga, R. and Montesano, L. and Minguez, J. and Millán, JdR},
	month = apr,
	year = {2014},
	pages = {036005},
	file = {IOP Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/HB5HIZZK/Iturrate et al. - 2014 - Latency correction of event-related potentials bet.pdf:application/pdf}
}

@article{parra_linear_2002,
	title = {Linear {Spatial} {Integration} for {Single}-{Trial} {Detection} in {Encephalography}},
	volume = {17},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811902912127},
	doi = {10.1006/nimg.2002.1212},
	abstract = {Conventionalanalysis of electroencephalography (EEG) and magnetoencephalography (MEG) often relies on averaging over multiple trials to extract statistically relevant differences between two or more experimental conditions. In this article we demonstrate single-trial detection by linearly integrating information over multiple spatially distributed sensors within a predefined time window. We report an average, single-trial discrimination performance of Az ≈ 0.80 and fraction correct between 0.70 and 0.80, across three distinct encephalographic data sets. We restrict our approach to linear integration, as it allows the computation of a spatial distribution of the discriminating component activity. In the present set of experiments the resulting component activity distributions are shown to correspond to the functional neuroanatomy consistent with the task (e.g., contralateral sensory–motor cortex and anterior cingulate). Our work demonstrates how a purely data-driven method for learning an optimal spatial weighting of encephalographic activity can be validated against the functional neuroanatomy.},
	language = {en},
	number = {1},
	urldate = {2019-11-01},
	journal = {NeuroImage},
	author = {Parra, Lucas and Alvino, Chris and Tang, Akaysha and Pearlmutter, Barak and Yeung, Nick and Osman, Allen and Sajda, Paul},
	month = sep,
	year = {2002},
	pages = {223--230},
	file = {ScienceDirect Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/9WZ8LE26/Parra et al. - 2002 - Linear Spatial Integration for Single-Trial Detect.pdf:application/pdf;ScienceDirect Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/JZU2U729/S1053811902912127.html:text/html}
}

@article{parra_recipes_2005,
	title = {Recipes for the linear analysis of {EEG}},
	volume = {28},
	issn = {1053-8119},
	url = {http://www.sciencedirect.com/science/article/pii/S1053811905003381},
	doi = {10.1016/j.neuroimage.2005.05.032},
	abstract = {In this paper, we describe a simple set of “recipes” for the analysis of high spatial density EEG. We focus on a linear integration of multiple channels for extracting individual components without making any spatial or anatomical modeling assumptions, instead requiring particular statistical properties such as maximum difference, maximum power, or statistical independence. We demonstrate how corresponding algorithms, for example, linear discriminant analysis, principal component analysis and independent component analysis, can be used to remove eye-motion artifacts, extract strong evoked responses, and decompose temporally overlapping components. The general approach is shown to be consistent with the underlying physics of EEG, which specifies a linear mixing model of the underlying neural and non-neural current sources.},
	language = {en},
	number = {2},
	urldate = {2019-11-01},
	journal = {NeuroImage},
	author = {Parra, Lucas C. and Spence, Clay D. and Gerson, Adam D. and Sajda, Paul},
	month = nov,
	year = {2005},
	keywords = {Brain computer interfaces, Electroencephalography (EEG), Generalized eigenvalue decomposition, Linear integration, Source estimation},
	pages = {326--341},
	file = {ScienceDirect Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/5ZQA2PBB/Parra et al. - 2005 - Recipes for the linear analysis of EEG.pdf:application/pdf;ScienceDirect Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/M3FQC4WR/S1053811905003381.html:text/html}
}

@article{duncan_event-related_2009,
	title = {Event-related potentials in clinical research: {Guidelines} for eliciting, recording, and quantifying mismatch negativity, {P}300, and {N}400},
	volume = {120},
	issn = {1388-2457},
	shorttitle = {Event-related potentials in clinical research},
	url = {http://www.sciencedirect.com/science/article/pii/S1388245709005185},
	doi = {10.1016/j.clinph.2009.07.045},
	abstract = {This paper describes recommended methods for the use of event-related brain potentials (ERPs) in clinical research and reviews applications to a variety of psychiatric and neurological disorders. Techniques are presented for eliciting, recording, and quantifying three major cognitive components with confirmed clinical utility: mismatch negativity (MMN), P300, and N400. Also highlighted are applications of each of the components as methods of investigating central nervous system pathology. The guidelines are intended to assist investigators who use ERPs in clinical research, in an effort to provide clear and concise recommendations and thereby to standardize methodology and facilitate comparability of data across laboratories.},
	language = {en},
	number = {11},
	urldate = {2019-11-01},
	journal = {Clinical Neurophysiology},
	author = {Duncan, Connie C. and Barry, Robert J. and Connolly, John F. and Fischer, Catherine and Michie, Patricia T. and Näätänen, Risto and Polich, John and Reinvang, Ivar and Van Petten, Cyma},
	month = nov,
	year = {2009},
	keywords = {Event-related potentials, P300, Clinical investigations, Guidelines, Mismatch negativity, MMN, N400},
	pages = {1883--1908},
	file = {ScienceDirect Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/5JSD678S/Duncan et al. - 2009 - Event-related potentials in clinical research Gui.pdf:application/pdf;ScienceDirect Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/548LLYBY/S1388245709005185.html:text/html}
}

@inproceedings{tomioka_classifying_2007,
	address = {New York, NY, USA},
	series = {{ICML} '07},
	title = {Classifying {Matrices} with a {Spectral} {Regularization}},
	isbn = {978-1-59593-793-3},
	url = {http://doi.acm.org/10.1145/1273496.1273609},
	doi = {10.1145/1273496.1273609},
	abstract = {We propose a method for the classification of matrices. We use a linear classifier with a novel regularization scheme based on the spectral l1-norm of its coefficient matrix. The spectral regularization not only provides a principled way of complexity control but also enables automatic determination of the rank of the coefficient matrix. Using the Linear Matrix Inequality technique, we formulate the inference task as a single convex optimization problem. We apply our method to the motor-imagery EEG classification problem. The method not only improves upon conventional methods in the classification performance but also determines a subspace in the signal that concentrates discriminative information without any additional feature extraction step. The method can be easily generalized to regression problems by changing the loss function. Connections to other methods are also discussed.},
	urldate = {2019-11-01},
	booktitle = {Proceedings of the 24th {International} {Conference} on {Machine} {Learning}},
	publisher = {ACM},
	author = {Tomioka, Ryota and Aihara, Kazuyuki},
	year = {2007},
	note = {event-place: Corvalis, Oregon, USA},
	pages = {895--902},
	file = {ACM Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/5VHS4S9R/Tomioka and Aihara - 2007 - Classifying Matrices with a Spectral Regularizatio.pdf:application/pdf}
}

@article{barachant_plug&play_2014,
	title = {A {Plug}\&{Play} {P}300 {BCI} {Using} {Information} {Geometry}},
	url = {http://arxiv.org/abs/1409.0107},
	abstract = {This paper presents a new classification methods for Event Related Potentials (ERP) based on an Information geometry framework. Through a new estimation of covariance matrices, this work extend the use of Riemannian geometry, which was previously limited to SMR-based BCI, to the problem of classification of ERPs. As compared to the state-of-the-art, this new method increases performance, reduces the number of data needed for the calibration and features good generalisation across sessions and subjects. This method is illustrated on data recorded with the P300-based game brain invaders. Finally, an online and adaptive implementation is described, where the BCI is initialized with generic parameters derived from a database and continuously adapt to the individual, allowing the user to play the game without any calibration while keeping a high accuracy.},
	urldate = {2019-11-04},
	journal = {arXiv:1409.0107 [cs, stat]},
	author = {Barachant, Alexandre and Congedo, Marco},
	month = aug,
	year = {2014},
	note = {arXiv: 1409.0107},
	keywords = {Computer Science - Human-Computer Interaction, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/GZZTEF2H/Barachant and Congedo - 2014 - A Plug&Play P300 BCI Using Information Geometry.pdf:application/pdf;arXiv.org Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/RL4S4YZB/1409.html:text/html}
}

@article{barachant_multiclass_2012,
	title = {Multiclass {Brain}-{Computer} {Interface} {Classification} by {Riemannian} {Geometry}},
	volume = {59},
	url = {https://hal.archives-ouvertes.fr/hal-00681328},
	doi = {10.1109/TBME.2011.2172210},
	abstract = {This paper presents a new classification framework for brain-computer interface (BCI) based on motor imagery. This framework involves the concept of Riemannian geometry in the manifold of covariance matrices. The main idea is to use spatial covariance matrices as EEG signal descriptors and to rely on Riemannian geometry to directly classify these matrices using the topology of the manifold of symmetric and positive definite (SPD) matrices. This framework allows to extract the spatial information contained in EEG signals without using spatial filtering. Two methods are proposed and compared with a reference method [multiclass Common Spatial Pattern (CSP) and Linear Discriminant Analysis (LDA)] on the multiclass dataset IIa from the BCI Competition IV. The first method, named minimum distance to Riemannian mean (MDRM), is an implementation of the minimum distance to mean (MDM) classification algorithm using Riemannian distance and Riemannian mean. This simple method shows comparable results with the reference method. The second method, named tangent space LDA (TSLDA), maps the covariance matrices onto the Riemannian tangent space where matrices can be vectorized and treated as Euclidean objects. Then, a variable selection procedure is applied in order to decrease dimensionality and a classification by LDA is performed. This latter method outperforms the reference method increasing the mean classification accuracy from 65.1\% to 70.2\%.},
	number = {4},
	urldate = {2019-11-04},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Barachant, Alexandre and Bonnet, Stéphane and Congedo, Marco and Jutten, Christian},
	month = mar,
	year = {2012},
	keywords = {Brain computer interfaces, electroencephalography, covariance matrix, classification algorithms, information geometry},
	pages = {920--928},
	file = {HAL PDF Full Text:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/3YAQGUV9/Barachant et al. - 2012 - Multiclass Brain-Computer Interface Classification.pdf:application/pdf}
}

@book{hyvarinen_independent_2001,
	address = {New York},
	edition = {1 edition},
	title = {Independent {Component} {Analysis}},
	isbn = {978-0-471-40540-5},
	abstract = {A comprehensive introduction to ICA for students and practitioners Independent Component Analysis (ICA) is one of the most exciting new topics in fields such as neural networks, advanced statistics, and signal processing. This is the first book to provide a comprehensive introduction to this new technique complete with the fundamental mathematical background needed to understand and utilize it. It offers a general overview of the basics of ICA, important solutions and algorithms, and in-depth coverage of new applications in image processing, telecommunications, audio signal processing, and more. Independent Component Analysis is divided into four sections that cover: * General mathematical concepts utilized in the book * The basic ICA model and its solution * Various extensions of the basic ICA model * Real-world applications for ICA models Authors Hyvarinen, Karhunen, and Oja are well known for their contributions to the development of ICA and here cover all the relevant theory, new algorithms, and applications in various fields. Researchers, students, and practitioners from a variety of disciplines will find this accessible volume both helpful and informative.},
	language = {English},
	publisher = {Wiley-Interscience},
	author = {Hyvärinen, Aapo and Karhunen, Juha and Oja, Erkki},
	month = may,
	year = {2001}
}

@book{hastie_elements_2009,
	address = {New York},
	edition = {2},
	series = {Springer {Series} in {Statistics}},
	title = {The {Elements} of {Statistical} {Learning}: {Data} {Mining}, {Inference}, and {Prediction}, {Second} {Edition}},
	isbn = {978-0-387-84857-0},
	shorttitle = {The {Elements} of {Statistical} {Learning}},
	url = {https://www.springer.com/gp/book/9780387848570},
	abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book. This major new edition features many topics not covered in the original, including graphical models, random forests, ensemble methods, least angle regression and path algorithms for the lasso, non-negative matrix factorization, and spectral clustering. There is also a chapter on methods for ``wide'' data (p bigger than n), including multiple testing and false discovery rates. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie co-developed much of the statistical modeling software and environment in R/S-PLUS and invented principal curves and surfaces. Tibshirani proposed the lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, projection pursuit and gradient boosting.},
	language = {en},
	urldate = {2019-11-04},
	publisher = {Springer-Verlag},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year = {2009},
	doi = {10.1007/978-0-387-84858-7},
	file = {Full Text:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/HIST3E9K/Hastie et al. - 2009 - The Elements of Statistical Learning Data Mining,.pdf:application/pdf;Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/PN4MJC7K/9780387848570.html:text/html}
}

@article{kutas_augmenting_1977,
	title = {Augmenting mental chronometry: the {P}300 as a measure of stimulus evaluation time},
	volume = {197},
	copyright = {© 1977},
	issn = {0036-8075, 1095-9203},
	shorttitle = {Augmenting mental chronometry},
	url = {https://science.sciencemag.org/content/197/4305/792},
	doi = {10.1126/science.887923},
	abstract = {A technique for measuring the latency of the P300 component of event-related brain potentials on individual trials is described. Choice reaction times and the latency of the P300 were compared under speed-maximizing and under accuracy-mazimising instructions. The choice stimuli required different levels of semantic categorization. The data support the proposition that the latency of P300 corresponds to stimulus evaluation time and is independent of response selection.},
	language = {en},
	number = {4305},
	urldate = {2019-11-06},
	journal = {Science},
	author = {Kutas, M. and McCarthy, G. and Donchin, E.},
	month = aug,
	year = {1977},
	pmid = {887923},
	pages = {792--795},
	file = {Snapshot:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/ZR3Z8X3G/792.html:text/html}
}

@article{wilson_procedure_2010,
	title = {A {Procedure} for {Measuring} {Latencies} in {Brain}–{Computer} {Interfaces}},
	volume = {57},
	issn = {0018-9294, 1558-2531},
	doi = {10.1109/TBME.2010.2047259},
	abstract = {Brain-computer interface (BCI) systems must process neural signals with consistent timing in order to support adequate system performance. Thus, it is important to have the capability to determine whether a particular BCI configuration (i.e., hardware and software) provides adequate timing performance for a particular experiment. This report presents a method of measuring and quantifying different aspects of system timing in several typical BCI experiments across a range of settings, and presents comprehensive measures of expected overall system latency for each experimental configuration.},
	number = {7},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Wilson, J. Adam and Mellinger, Jürgen and Schalk, Gerwin and Williams, Justin},
	month = jul,
	year = {2010},
	keywords = {Signal Processing, Computer-Assisted, Brain–computer interface (BCI), Models, Neurological, Delay, Control systems, BCI, Brain, Brain-Computer Interfaces, Computer Systems, Electroencephalography, Evoked Potentials, Humans, Reproducibility of Results, Time Factors, User-Computer Interface, medical signal processing, Biomedical imaging, brain-computer interfaces, electroencephalography, neurophysiology, BCI2000, Biomedical engineering, Biomedical measurements, electrocorticography, Hardware, neural signals, Operating systems, real time, Signal processing, system latency, system timing, timing, Timing},
	pages = {1785--1797},
	file = {IEEE Xplore Abstract Record:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/KJJKKELZ/5447739.html:text/html;IEEE Xplore Full Text PDF:/home/ruslan/.zotero/zotero/u3gbzawz.default/zotero/storage/29SPTQHL/Wilson et al. - 2010 - A Procedure for Measuring Latencies in Brain–Compu.pdf:application/pdf}
}