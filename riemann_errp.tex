
%    INSTITUTE OF PHYSICS PUBLISHING                                   %
%                                                                      %
%   `Preparing an article for publication in an Institute of Physics   %
%    Publishing journal using LaTeX'                                   %
%                                                                      %
%    LaTeX source code `ioplau2e.tex' used to generate `author         %
%    guidelines', the documentation explaining and demonstrating use   %
%    of the Institute of Physics Publishing LaTeX preprint files       %
%    `iopart.cls, iopart12.clo and iopart10.clo'.                      %
%                                                                      %
%    `ioplau2e.tex' itself uses LaTeX with `iopart.cls'                %
%                                                                      %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%
% First we have a character check
%
% ! exclamation mark    " double quote  
% # hash                ` opening quote (grave)
% & ampersand           ' closing quote (acute)
% $ dollar              % percent       
% ( open parenthesis    ) close paren.  
% - hyphen              = equals sign
% | vertical bar        ~ tilde         
% @ at sign             _ underscore
% { open curly brace    } close curly   
% [ open square         ] close square bracket
% + plus sign           ; semi-colon    
% * asterisk            : colon
% < open angle bracket  > close angle   
% , comma               . full stop
% ? question mark       / forward slash 
% \ backslash           ^ circumflex
%
% ABCDEFGHIJKLMNOPQRSTUVWXYZ 
% abcdefghijklmnopqrstuvwxyz 
% 1234567890
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\pdfminorversion=4

\documentclass[12pt]{iopart}
\usepackage{graphicx}
\usepackage{amssymb}
%\usepackage{amsmath}
\newcommand{\gguide}{{\it Preparing graphics for IOP Publishing journals}}
%Uncomment next line if AMS fonts required
%\usepackage{iopams}  
\begin{document}

\title[]{Stability of spatial covariance in ERPs with high temporal variability}

\author{R Aydarkhanov$^1$,
M Uscumlic$^2$,
R Chavarriaga$^3$,
J d R Millan$^4$}


\address{$^1$EPFL, Switzerland}
\address{$^2$EPFL, Switzerland}
\address{$^3$EPFL, Switzerland}
\address{$^4$TU Austin, USA}
\ead{ruslan.aydarkhanov@epfl.ch}
\vspace{10pt}
%\begin{indented}
%\item[] August 2017
%\end{indented}

\begin{abstract}
Event Related Potentials (ERPs) are widely used in Brain Computer
Interfaces (BCI) by providing a cognitive evaluation to external stimuli.
ERPs are characterized and typically decoded through a fixed set of
components with particular amplitude and latency. 
However, the classical methods which rely on waveform features
achieve a high decoding performance only with standardized
and well aligned single trials. Since the amplitude and latency
are sensitive to the experimental conditions,
waveform features cannot be applied for challenging tasks and
to generalize across various experimental protocols.
Signal features based on spatial covariances can potentially overcome
the latency jitter and delays since they aggregate the information
across time. We compared the performance stability 
of waveform and covariance-based features as well as their combination
in simulated scenarios such as classifier transfer 
and increased single-trial latency variability.
Our findings suggest that covariance-based features
can be used to: 1) classify more reliably ERPs
with higher intrinsic variability in more challenging real-life applications
and 2) generalize across related experimental protocols.
\end{abstract}

%
% Uncomment for keywords
\vspace{2pc}
\noindent{\it Keywords\/}: Brain-computer interfaces, Electroencephalography, Riemannian geometry
%
% Uncomment for Submitted to journal title message
%\submitto{\JPA}
%
% Uncomment if a separate title page is required
%\maketitle
% 
% For two-column output uncomment the next line and choose [10pt] rather than [12pt] in the \documentclass declaration
%\ioptwocol
%



\section{Introduction}
\label{sec:intro}

Brain Computer Interfaces provide novel means of interacting
with machines. The most efficient technology to acquire
the neural signal non-invasively is electroencephalography (EEG) \cite{luck_introduction_2005}.
There exist various well-established EEG-based BCI paradigms which
provide a high performance and rely on such phenomena as
Sensory-Motor Rhythms (SMR), Steady-State Evoked Potentials (SSEP),
or Event-Related Potentials (ERP).
For each paradigm a specific data processing and feature
extraction steps are required.
Despite the high performance in sterile laboratory
conditions, the challenge to bring EEG-based BCI to real life
still remains. In this paper we explore popular approaches to decode ERPs
which are often challenged by temporal variability of single trials.
An Event-Related Potential is a brain response to an external event.
The most widely used ERPs in BCI include P300 and ErrP which
reflect a cognitive process of event evaluation.
P300 is elicited upon presentation of a rare stimuli in the oddball paradigm
and it is associated with stimulus categorization whereas
ErrP is observed when errors are committed by the user, other people or machines.

For BCI application ERPs are classified into one of the two categories 
based on the EEG signal generated after the event.
ERP waveforms consist of multiple components characterized
by a particular latency, polarity and spatial distribution \cite{duncan_event-related_2009}.
One of the classical approaches to decode ERPs is to 
use the signal amplitude at specific time points and channels as features
for a binary classifier.
As opposed to Evoked Potentials triggered by a simple sensory stimulation,
ERPs are generally associated with higher cognitive processing
and, therefore, increased latency. The latency is not only greater, it can
vary across different yet similar tasks and become variable
at challenging tasks \cite{arico_evaluation_2013}. 
This inconsistency complicates the decoding of ERP on single trials.
Thus, the interaction
protocol needs to be carefully adjusted and the decoding
algorithm finely tuned for each scenario \cite{iturrate_task-dependent_2013}.

Another way to process ERP signal is to extract features based on spatial covariance matrices
which emphasize the pair-wise interaction
between channels and the total variance of single channels.
Covariance matrices can be used directly \cite{tomioka_classifying_2007}, but
they are typically transformed by means of Riemannian geometry 
\cite{barachant_classification_2013, zanini_transfer_2018}.
It has proven to provide performance compared to other frequently used
approaches in BCI, e.g. waveform features or 
features extracted with CSP \cite{blankertz_optimizing_2008}.
One of the disadvantages of
EEG spatial covariance matrix is the loss of precise temporal dynamics.
A typical solution against this problem is to augment the matrix
with the covariances between single trial and a preselected template,
e.g. an averaged ERP of one of the classes \cite{congedo_new_2013,barachant_plug&play_2014}.

In this study, we explore both popular approaches to classify ERPs
under the challenges of temporal variability. 
Specifically, we compare waveform vs covariance features,
the benefits of their combination and the impact of Riemannian geometry vs Euclidean geometry.
We simulate two scenarios. Firstly, we simulate the high temporal
variability by artificially introducing the latency jitter in the 
trial extraction. Secondly, we transfer the classifier between
different yet related protocols.


%In this study we explore the robustness of covariance-derived features
%in decoding ERPs to the various perturbations of latency
%and compare them with more traditional temporal waveform features.

%Although one can use the values from covariance matrix
%directly as features for the classifier \cite{tomioka_classifying_2007}, Euclidean geometry is not 
%suitable to describe their relationships \cite{arsigny_geometric_2007}. 
%Since they are 
%Symmetric Positive Definite matrices (SPD),
%they are better characterized in terms of Riemannian geometry.

%It shows promising
%results in generalization across sessions \cite{barachant_classification_2013}
%and transfer learning across subjects \cite{zanini_transfer_2018}.



\section{Materials and Methods}
\label{sec:methods}
\subsection{Data}
We choose the dataset which contains recordings from multiple protocols
on Error-related Potentials (ErrP) \cite{iturrate_latency_2014-1}. It will allow us to test
the transfer learning in real application in addition to theoretical
investigations and simulations.
In all the protocols participants observed a discrete movement of an object
on the visual display or in physical space.
They evaluated the movement as correct if the object moved towards a marked target or erroneous 
otherwise. The evaluation was made without an overt behavioral response.

In Experiment 1 ($E_1$) a one-dimensional space with 9 positions was shown on a visual display and
a blue square was moving towards a red square (target). In Experiment 3 ($E_3$) participant were seated
in front of a robotic arm, 2 meters away with a transparent panel in between.
The panel contained squared marks in a regular grit forming a two-dimensional space.
The robotic arm moved behind the marks up, down, left or right 
towards one of the corners (targets).
Experiment 2 ($E_2$) was a virtual version of Experiment 3 in which marks and the robotic arm
were rendered on a visual display.
The probability of the erroneous
movement was approximately 30\%. The time between consecutive movements was randomly sampled
from the range [1.7, 4.0] s. 
6 subjects participated in three ErrP experiments.
Further details about the protocols can be found in \cite{iturrate_latency_2014-1}.

The three experiments have a similar ERP waveform 
while having systematic difference in latency (Figure \ref{fig:FCz}).
The latency differences are previously estimated to be:
60.42 $\pm$ 25.24, 108.85 $\pm$ 22.86 and 41.02 $\pm$ 12.95 ms
for the $E_1 E_2$, $E_1 E_3$, and $E_2 E_3$ pair of experiments.
A linear classifier
based on waveform features cannot cope with it when trained and applied
on different datasets, the performance drops to random level
for considerable latency shifts. However, a simple correction of 
the latency allows to recover the performance up to the level
obtained within the single protocol dataset  \cite{iturrate_latency_2014-1}.


\begin{figure}[!t]
    \includegraphics[trim={0cm 0cm 0 0cm},clip,width=\columnwidth]{../images/FCz_all_diff_Topo_compact.pdf}
\caption{Grand averages for all three experiments. The waveforms show the difference between
Error and Correct trials at FCz channel. Topographies show the amplitudes for P3 and N4 peaks.}
\label{fig:FCz}
\end{figure}


\subsection{Covariance-based features}

Different sources of neural activity project at the scalp with a specific distribution.
Spatial covariances between EEG channels capture the shape of this distribution
and the strength of the activity averaged across the time-window of interest.
Covariance matrices can be built in different ways.
The simple estimation is done as follows: 
$\mathbf{C} = \frac{1}{s}\mathbf{X}^T\mathbf{X}$ where $\mathbf{X} \in \mathbb{R}^{s \times n}$ is a multichannel
EEG epoch with $n$ channels and $s$ time points.
In case of ERPs, this estimation looses the precise temporal dynamics of the waveform.
In order to compensate for this, a modified version of covariance matrices
was suggested \cite{congedo_new_2013}. 
The epoch $\mathbf{X}$ is augmented with a template $\mathbf{T} \in \mathbb{R}^{s \times k}$
along the channel dimension to build a super epoch
$\mathbf{Z} = [\mathbf{X} \quad \mathbf{T}] \in \mathbb{R}^{s \times (n + k)}$.
The covariance matrix estimated on the augmented signal becomes:
\begin{equation}
    \mathbf{C}_\mathbf{T} = \frac{1}{s}\mathbf{Z}^T\mathbf{Z} = \frac{1}{s}
    \pmatrix{
        \mathbf{X}^T\mathbf{X} & \mathbf{X}^T\mathbf{T} \cr
        \mathbf{T}^T\mathbf{X} & \mathbf{T}^T\mathbf{T} 
    }
    \label{eq:templ}
\end{equation}

The covariance between $\mathbf{X}$ and $\mathbf{T}$ allows to capture the temporal dynamics
specifically with the relation to the template $\mathbf{T}$. In the context of ERP
experiments, the template is typically an average ERP of one or several classes.
In this case it will reflect how similar a particular epoch is to the average ERP.
Thus the covariance matrix $\mathbf{C}_\mathbf{T}$ contains the combination
of two sources of information: covariances between channels and the similarity to the template waveform.

In high dimensional settings a simple Maximum Likelihood Estimator of covariance matrix is not
stable so a regularization is often applied. In this paper we use
a shrinkage as described in \cite{chen_shrinkage_2010}.

\subsubsection{Riemannian geometry on covariance matrices}
The natural choice to treat covariance matrices is to vectorize them
and use as a feature vector for further processing and classification.
But most vector-based algorithms assume a Euclidean space, such as PCA \cite{hyvarinen_independent_2001}.
Euclidean geometry is not well suited for SPD matrices due to various
drawbacks \cite{arsigny_geometric_2007}, so they can be characterized 
better with Riemannian geometry while improving the performance.
For example, a popular approach relying on covariance matrices for feature extraction,
namely, Common Spatial Patterns (CSP) can be improved within Riemannian framework \cite{barachant_common_2010}.

Riemannian geometry is the branch of mathematics that studies
smooth spaces locally behaving like a Euclidean space.
The main feature of Riemannian space consists in the way the distances are defined.
While Euclidean space has a constant distance metric in all points,
the Riemannian metric smoothly changes along the space.
As a simple visual example, imagine a curvy surface of a sphere.
Although the surface is is a 2-dimensional space,
we cannot directly compute the distance between 2 remote points.
However, around each point distances can be locally approximated
with $\mathbb{R}^2$ Euclidean space.

One of the simple ways to introduce the benefits from Riemannian geometry
into classification of covariance matrices is to use their projection
on a tangent space \cite{barachant_multiclass_2012}. The tangent space is a Euclidean space which allows
to leverage the standard vector-based algorithms.
The approach requires two steps:
\begin{enumerate}
    \item To find a geometric mean $\bar{\mathbf{C}}$ of the sample of covariance matrices:
        \begin{equation}
            \bar{\mathbf{C}} = \textrm{argmin}_\mathbf{C} \sum_{i=1}^N \delta^2 (\mathbf{C}_i, \mathbf{C})
            \label{eq:geommean}
        \end{equation}
        where $\mathbf{C}_i$ denotes a covariance matrix, and $\delta$ is a 
        Riemannian distance between covariance matrices.
    \item The relationship between covariance matrices can be approximated with
        Euclidean geometry around the geometric mean $\bar{\mathbf{C}}$ by projecting them on a tangent
        space $\mathbf{S}_{\bar{\mathbf{C}}}$:
        \begin{equation}
            \mathbf{S}_{\bar{\mathbf{C}}} = \bar{\mathbf{C}}^{1/2}
            \textrm{logm}(\bar{\mathbf{C}}^{-1/2}\mathbf{C}\bar{\mathbf{C}}^{-1/2})\bar{\mathbf{C}}^{1/2}
            \label{eq:logm}
        \end{equation}
        where $\textrm{logm}$ denotes the logarithm of a matrix \cite{berger_panoramic_2003}.
\end{enumerate}

\subsection{Data processing and feature extraction}
All the EEG was filtered with Butterworth band-pass filter of order 4 within the band [1, 10] Hz
forward and backward and downsampled from 512 Hz to 128 Hz. Then the signal is spatially
filtered with common-average-reference (CAR). Further feature extraction is done
from time window of [200, 1000] ms after the event. We explore and compare different sets
of features, which include ERP waveform and covariance matrices.

For the classification we prepare the following features:
\begin{enumerate}
    \item Waveform of the ERP, i.e. the amplitude at all channels and time points. Due to high
        dimensionality (1648) we apply PCA and keep components with highest eigenvalue
        which explain 90\% of the variance. It resulted into 60 +/- 8 features.
    \item Covariance matrices computed with shrinkage to improve stability bringing 136 features.
    \item Projections of shrinkaged covariance matrices on a tangent space. The projection reference
        point is the geometric mean estimated from the training data.
    \item Shrinkaged covariance matrices estimated on super epochs augmented with the averaged ERPs
        of each class. ERPs were estimated from the training data.
        Such an augmentation produces
        a high number of features (1176) so we decided to preselect 8 channels which
        drastically reduces the number of features to 300. We automatically choose
        the channels according to the mean Fisher score across all time points \cite{duda_pattern_2001}.
\end{enumerate}

\subsection{Feature evaluation}

For the binary classification we apply penalized logistic
regression (PLR) because it is robust to overfiting and outliers \cite{parra_recipes_2005},
the regularization parameter is optimized with 4-fold cross validation
while keeping the temporal relationships for splitting. 
Additionally, we standardize all features by z-score with mean and standard deviation
obtained from the training data because we use a regularized classifier \cite{hastie_elements_2009}.
Since the classes
are not balanced in ErrP protocols, we measure the performance by area under the ROC curve (AUC) 
\cite{bradley_use_1997}.

As a baseline we estimate the performance of all features in a leave-one-run-out cross validation.
Together with the hyperparameter optimization the overall procedure is structured as
a nested cross validation.
High performance with a linear classifier suggests that ERP waveforms are consistent
across single trials. In order to test the robustness of different features
to the temporal variability we introduce a random jitter to the time window
for all the epochs. The amount of jitter is sampled from a uniform distribution.
Three gradual jitter levels are [-50, 50], [-100, 100], [-200, 200] and [-300, 300] ms.
This procedure is repeated on all three experiments.

The three experiments proved to evoke similar-shaped ErrP with a 
systematic shift in latency. Without any fine-tuning and additional
transformation we transfer classifiers within the same subject
between experiments. Classifier trained on one experiment
is tested on the other two, providing a single AUC number per pair.
This procedure is repeated for all pairs of the experiments and all feature sets.


\section{Results}
\label{sec:results}

\subsection{Performance on the jitter-free dataset}

\begin{figure}[!t]
    \includegraphics[trim={1cm 1.5cm 0 2.2cm},clip,width=\columnwidth]{../images/RiemannERP_Jitter_Summary.png}
\caption{Robustness of the classifiers to artificial temporal jitter.
    Each figure represents one of the experiments. The data shows
    AUC as mean and standard deviation across all subjects.}
\label{fig:jitter}
\end{figure}

First of all, we can see that all classifiers perform well on the
original datasets without jitter \ref{fig:jitter}. The average AUC across subjects is between 75 and 90.
There is a statistically significant difference across classifiers obtained with two-way repeated
measures ANOVA, the factors being the classifier and the experiments (p-value $< 0.001$
(0.000186)). By breaking down the difference into pair-wise comparison with post-hoc
two-way repeated measures ANOVA, we can see that the difference is mainly driven by
``Riemann + ERP'' classifier (p-value $< 0.01$ for all pair-wise comparisons with other
classifiers). So the combination of the all features gives the best results. Processing of
covariance matrices with Riemannian geometry significantly improves the performance
as opposed to Euclidean geometry (p-value $= 0.03$).


\subsection{Robustness to jitter}

The performance change for different levels of jitter is shown on Figure \ref{fig:jitter}.
The overall trend is the reduction in performance with the increase in temporal jitter for all classifiers.
The significance of the effect is tested on each experiment independently
with 2-way repeated measures ANOVA for the jitter level and the classifier
as factors. Both main effects are significant (p-values $<0.001$). 
Regardless the experiment, the strongest effect is obtained for the interaction
of factors (p-values $< 0.0001$) for all the experiments. The performance decreases more
rapidly with jitter for ERP waveform features.
Pure covariance matrices are most stable against the jitter regardless of whether they are
treated with Euclidean or Riemannian geometry.

\subsection{Classifier transfer between protocol}
We assessed all classifiers for all possible pairs of training 
and testing datasets (Figure \ref{fig:transfer}).
In contrast to the within-dataset performance, combination of features
does not provide best results when transferring between protocols.
Waveform features demonstrate the biggest drop
in performance. The transfer between $E_1$ and either $E_2$ or $E_3$
leads to a random classification. The respective latencies are shifted by 60 and 100ms.
In the meantime covariance matrices are more robust
especially when the latency shift is bigger.
There is a statistically significant difference across classifiers
for all training/test pairs, with p-values $< 0.0001$ (one-way ANOVA).
Interestingly, there is no difference in performance between simple covariance matrices
and the ones transformed with Riemannian geometry.


\begin{figure*}[!t]
    \centerline{\includegraphics[trim={2.5cm 0cm 3cm 0.5cm},clip,width=\columnwidth]{../images/RiemannERP_Transfer_Matrix.png}}
    \caption{Cross-protocol classifier transfer. First three matrices show AUC estimated
    on test dataset (y-axis) with a classifier trained on a training dataset (x-axis).
    The right-most matrix provides p-values obtained with ANOVA when comparing classifiers
    for each train/test pair.}
\label{fig:transfer}
\end{figure*}

\section{Discussion}
\label{sec:discussion}

Classification of ERPs provides a basis for various BCI applications.
Decoding of ERPs can be done with a high accuracy in restrictive conditions.
The stimuli must be clear and simple to recognize
in order to evoke a standardized EEG waveform. And the classifier
must be fine-tuned for the given ERP waveform.
In order to ensure a high performance of a system the algorithm
is trained individually for each subject and each experiment.
Although there is a limited number of ERP types used in practice,
it is not always feasible to train a single classifier. 
Even a small
modification such as a transition from 1D to 2D scenario or virtual to physical
can influence the ERP shape and latency. More complex stimuli
could also lead to a higher variability of ERP within the same protocol.
Latency is mainly affected by the stimulus evaluation time \cite{kutas_augmenting_1977}.

In this study we verified the robustness of different types of features
to the variability and shifts in latency using real ErrP data.
It is done in two ways: through artificial latency jitter
and classifier transfer between different protocols.
For our experiments we selected a dataset obtained on three
different ErrP protocols. The ERPs within each protocol are
well aligned but had a latency differences between them.

We showed that both types of features spatial covariances and the ERP waveform
carry sufficient information for high performance above 75 AUC points.
Waveform features contain more discriminant power on the original datasets.
But the method which combines both channel covariances and the waveform
provides the highest performance.
However, when challenged with the shifts in latency
spatial covariance features are more robust.
In both scenarios with classifier transfer and latency jitter
the combination of features leads to an intermediate
performance as compared to simple sets of features.

These findings can lead to improved performance in ERP-based BCI. 
There is no solution that can fit all application cases.
It is not always feasible to assess the temporal variability
of ERPs, so a new experimental scenarios both approaches
could be evaluated.
However, experiments with ambiguous and complex stimuli which require more time
for evaluation could benefit from temporally robust covariance features.
Better generalization capabilities can also allow a more efficient and quick
calibration procedure in case of the transfer between related protocols.


\section*{References}

\bibliographystyle{unsrt}
\bibliography{RiemannERP_paper.bib}

\end{document}

